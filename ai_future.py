# -*- coding: utf-8 -*-
"""Ai_Future.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yznsZ96s1NZ2mo0DUc4B3SKZIdsFUlb
"""

import os
import tensorflow as tf
print('TensorFlow', tf.__version__)

DATA_DIR = 'dataset'
BATCH_SIZE = 32
IMG_SIZE = (224, 224)

from tensorflow.keras.preprocessing import image_dataset_from_directory
import numpy as np
from PIL import Image
import os # Ensure os is imported, though it usually is

# Create dummy directories and files for demonstration if they don't exist
train_dummy_dir = os.path.join(DATA_DIR, 'train', 'dummy_class')
val_dummy_dir = os.path.join(DATA_DIR, 'val', 'dummy_class')
dummy_image_path_train = os.path.join(train_dummy_dir, 'dummy_image.jpg')
dummy_image_path_val = os.path.join(val_dummy_dir, 'dummy_image.jpg')

# Ensure directories exist (create if they don't)
os.makedirs(train_dummy_dir, exist_ok=True)
os.makedirs(val_dummy_dir, exist_ok=True)

# Always create or overwrite the dummy image files as valid JPEGs
img = Image.fromarray(np.zeros((IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.uint8))
img.save(dummy_image_path_train)
img.save(dummy_image_path_val)

train_ds = image_dataset_from_directory(os.path.join(DATA_DIR, 'train'),
                                       image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=True)
val_ds = image_dataset_from_directory(os.path.join(DATA_DIR, 'val'),
                                     image_size=IMG_SIZE, batch_size=BATCH_SIZE)
class_names = train_ds.class_names
print('Classes:', class_names)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)
data_augmentation = tf.keras.Sequential([
tf.keras.layers.RandomFlip('horizontal'),
tf.keras.layers.RandomRotation(0.05),
tf.keras.layers.RandomZoom(0.1),
])

base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),
                                               include_top=False, weights='imagenet')
base_model.trainable = False

# --- Model for training (includes data augmentation) ---
inputs_train = tf.keras.Input(shape=(224,224,3))
x_train = data_augmentation(inputs_train)
x_train = tf.keras.layers.Rescaling(1./127.5, offset=-1)(x_train)
x_train = base_model(x_train, training=False)
x_train = tf.keras.layers.GlobalAveragePooling2D()(x_train)
x_train = tf.keras.layers.Dropout(0.2)(x_train)

# Adjust output layer and loss based on the number of classes for the training model
if len(class_names) <= 2:
    outputs_train = tf.keras.layers.Dense(1, activation='sigmoid')(x_train)
    loss_fn = 'binary_crossentropy'
else:
    outputs_train = tf.keras.layers.Dense(len(class_names), activation='softmax')(x_train)
    loss_fn = 'sparse_categorical_crossentropy'

model = tf.keras.Model(inputs_train, outputs_train)
model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])
model.summary()

# --- Model for TFLite conversion (excludes data augmentation) ---
# This model will perform preprocessing directly
inference_inputs = tf.keras.Input(shape=(224,224,3))
x_inference = tf.keras.layers.Rescaling(1./127.5, offset=-1)(inference_inputs)
x_inference = base_model(x_inference, training=False)
x_inference = tf.keras.layers.GlobalAveragePooling2D()(x_inference)
x_inference = tf.keras.layers.Dropout(0.2)(x_inference)

# The output layer for inference should be the same as training
if len(class_names) <= 2:
    inference_outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x_inference)
else:
    inference_outputs = tf.keras.layers.Dense(len(class_names), activation='softmax')(x_inference)

inference_model = tf.keras.Model(inference_inputs, inference_outputs)

EPOCHS = 8
history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)

loss, acc = model.evaluate(val_ds)
print('Val accuracy:', acc)
# Save model
os.makedirs('models', exist_ok=True)
model.save('models/mobilenetv2_recycle.h5')

# Save SavedModel using model.export() for better compatibility
# Use the inference_model for TFLite conversion later
inference_model.export('models/saved_model_inference')

# Save SavedModel
model.export('models/saved_model') # Changed to model.export() for better compatibility

# Float TFLite for the inference model
converter = tf.lite.TFLiteConverter.from_saved_model('models/saved_model_inference')
model_tflite = converter.convert()
open('models/mobilenetv2_recycle.tflite', 'wb').write(model_tflite)
print('Wrote models/mobilenetv2_recycle.tflite')

# Quantized (dynamic range) for the inference model
converter.optimizations = [tf.lite.Optimize.DEFAULT]
model_tflite_q = converter.convert()
open('models/mobilenetv2_recycle_quant.tflite', 'wb').write(model_tflite_q)
print('Wrote models/mobilenetv2_recycle_quant.tflite')

def representative_data_gen():
    for images, _ in train_ds.take(100):
        # Ensure images are preprocessed as expected by inference_model
        yield [tf.keras.layers.Rescaling(1./127.5, offset=-1)(tf.cast(images, tf.float32))]

# Use 'saved_model_inference' for TFLite conversion
converter = tf.lite.TFLiteConverter.from_saved_model('models/saved_model_inference')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
model_tflite_int8 = converter.convert()
open('models/mobilenetv2_recycle_int8.tflite', 'wb').write(model_tflite_int8)
print('Wrote models/mobilenetv2_recycle_int8.tflite')

import numpy as np
import PIL.Image as Image
interpreter = tf.lite.Interpreter(model_path='models/mobilenetv2_recycle_quant.tflite')
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_shape = input_details[0]['shape']
# example prediction function
def predict_tflite(img_path):
  img = Image.open(img_path).resize((224,224)).convert('RGB')
  input_data = np.array(img)[None, ...].astype(np.float32)
  interpreter.set_tensor(input_details[0]['index'], input_data)
  interpreter.invoke()
  output_data = interpreter.get_tensor(output_details[0]['index'])
  return output_data[0]
# Run on a sample image
print(predict_tflite(os.path.join(DATA_DIR, 'val', class_names[0],
os.listdir(os.path.join(DATA_DIR, 'val', class_names[0]))[0])))

import time
N=50
img_path = os.path.join(DATA_DIR, 'val', class_names[0],
os.listdir(os.path.join(DATA_DIR, 'val', class_names[0]))[0])
start = time.perf_counter()
for i in range(N):
  predict_tflite(img_path)
end = time.perf_counter()
print('Avg inference ms:', (end-start)/N*1000)

import argparse
import time
import numpy as np
from PIL import Image
import os
try:
  import tflite_runtime.interpreter as tflite
except Exception:
  import tensorflow as tf
  tflite = tf.lite
def load_image(path, size=(224,224)):
  img = Image.open(path).convert('RGB').resize(size)
  return np.array(img)
def main(model_path, image_path):
  interpreter = tflite.Interpreter(model_path=model_path)
  interpreter.allocate_tensors()
  input_details = interpreter.get_input_details()
  output_details = interpreter.get_output_details()
  img = load_image(image_path)
  input_data = np.expand_dims(img, axis=0).astype(np.float32)
  # Warm-up
  interpreter.set_tensor(input_details[0]['index'], input_data)
  interpreter.invoke()
  # Timed runs
  runs = 50
  t0 = time.perf_counter()
  for _ in range(runs):
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()
  t1 = time.perf_counter()
  avg_ms = (t1 - t0)/runs*1000
  output = interpreter.get_tensor(output_details[0]['index'])
  print('Output vector (first 10):', output[0][:10])
  print(f'Avg inference time over {runs} runs: {avg_ms:.2f} ms')

if __name__ == '__main__':
  # Provide hardcoded arguments for Colab execution
  model_to_test = 'models/mobilenetv2_recycle_quant.tflite'
  # Ensure img_path is defined from previous cells or redefine here
  # Assuming img_path from previous execution context is still valid
  image_to_test = os.path.join(DATA_DIR, 'val', class_names[0],
                              os.listdir(os.path.join(DATA_DIR, 'val', class_names[0]))[0])
  main(model_to_test, image_to_test)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
# Simulation parameters
np.random.seed(42)
DAYS = 365*3 # 3 years of daily data
# Simulate seasonal temperature
t = np.arange(DAYS)
seasonal_temp = 10 + 10*np.sin(2*np.pi*t/365)
# Soil moisture random walk influenced by rainfall
rain = (np.random.rand(DAYS) < 0.05).astype(float) * np.random.uniform(5,
30,size=DAYS)
soil_moisture = np.zeros(DAYS)
soil_moisture[0] = 30
for i in range(1, DAYS):
  soil_moisture[i] = max(0, soil_moisture[i-1] - 0.1 + 0.5*rain[i] +
np.random.normal(scale=0.5))
# NDVI-like signal influenced by soil moisture and temp
ndvi = 0.4 + 0.003*soil_moisture + 0.001*seasonal_temp + np.random.normal(scale=0.01, size=DAYS)
# Yield (kg/ha) per day as a latent variable (sum over season)
yield_signal = ndvi * (soil_moisture/50) * (seasonal_temp/20)
# Aggregate to seasonal yield: compute yearly yield labels for training
years = DAYS // 365
labels = []
features = []
for y in range(years):
  start = y*365
  end = start + 365
# features: mean soil moisture, mean temp, mean ndvi for the year
  feats = [soil_moisture[start:end].mean(), seasonal_temp[start:end].mean(),
  ndvi[start:end].mean()]
  features.append(feats)
  labels.append(yield_signal[start:end].sum())
X = np.array(features)
y = np.array(labels)
# Train simple regressor (dense) for demonstration
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)
model = GradientBoostingRegressor()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print('Simulated dataset MSE:', mean_squared_error(y_test, y_pred))
# Save model (optional) and plot
import joblib
import os
os.makedirs('iot-design', exist_ok=True) # Create the directory if it doesn't exist
joblib.dump(model, 'iot-design/sim_gbr_model.joblib')
plt.scatter(y_test, y_pred)
plt.xlabel('True yield')
plt.ylabel('Predicted yield')
plt.title('Simulated yield predictions')
plt.savefig('iot-design/sim_yield_scatter.png')
print('Simulation complete. Plotted results to iot-design/sim_yield_scatter.png')